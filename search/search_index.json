{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Projek AIHUB Visi Misi AIHUB.ID Projek Aihub adalah projek swadaya, kolaborasi bersama antara masyarakat pelaku IT, Pemerintah Daerah, Universitas dan pihak pihak yang bersedia membantu baik dana, infrastruktur ataupun kajian ilmiah. Projek ini tidak terafiliasi kepada partai politik manapun dan pihak pihak manapun. Tujuan aihub adalah membangun sebuah tata kelola Big Data yang portable, mudah dipakai dan mudah diimplementasi dalam ekosistim Big Data menggunakan teknologi Apache Hadoop, Apache Spark, Apache Parquet dan Apache Drill, pustaka Machine Learning Python, Odoo Framework dan lainnya diatas Sistem Operasi Linux (Ubuntu Server) untuk deployment rack to rack ataupun Ubuntu server dengan manajemen container LXD untuk mesin hypervisor Sejarah Projek AIHUB Projek pembuatan sistem tata kelola big data ini dimulai pada bulan February 2017, dengan nama projek Asclepius, yaitu sebuah projek kerjasama antara Dinas Kesehatan Kota Cimahi , Team Ahli IT dari berbagai lapisan masyarakat dan PT. Mediblok Rekatama Indonesia. Tujuan projek Asclepius ini adalah membangun sebuah machine learning kesehatan yang mampu memetakan sebaran penyakit di Kota Cimahi. Projek ini dapat diakses di http://asclepius.medblocks.id . Projek Asclepius selain melibatkan Pemerintah Daerah dan swadaya masyarakat juga dibantu oleh beberapa pihak yaitu PT. Masterweb Network untuk penyediaan infrastruktur dan Telkomsel untuk pengembangan sistem. Sejak tahun 2018, Projek Asclepius ini banyak menyita perhatian masyarakat baik dalam negeri maupun luar negeri, dan dikarenakan oleh saran dari semua pihak maka di tahun 2019 projek ini berubah nama menjadi projek AIHUB yang pengelolaan nya diatur secara swadaya serta melibatkan pihak pihak yang tertarik untuk ikut terlibat dalam pengembangan. Sebagai sebuah projek yang berkesinambungan, projek ini terbuka bagi semua orang yang ingin terlibat, saat ini, pengelolaan projek AIHUB diatur sebagai berikut : Team Teknis Penanggung Jawab Utama , Hardiyanto dari Vision Development Group Singapore Hubungan Masyarakat, Hera Satriono, Perwakilan Swadaya Masyarakat Teknologi Informasi Penanggung jawab Teknis, Whisnu Budhysantika, Perwakilan Swadaya Masyarakat Teknologi Informasi Dewan Pengkajian dan Penelitian : dr. Dwi Agustian, MPH, PhD, Kepala Departemen Ilmu Kesehatan Masyarakat Fakultas Kedokteran Universitas Padjadjaran Bandung Fakultas Kedokteran Universitas Jendral Achmad Yani Cimahi JSPS, Japan Society for Promotion of Science, Jepang Dewan Penasihat : Vina, Septiarani, PhD. Badan Perencanaan Daerah Kota Cimahi dr. Mariya Mubarika Rachman, Staff Khusus Kementrian Kesehatan Indonesia Pihak Sponsor : PT. Masterweb Network Indonesia (2017 - 2018) Telkomsel Indonesia (2018) Shinkowa Pharmaeutical Co. Ltd, Jepang (2019) Press Releases dan kunjungan tamu peninjau BOT, Lembaga Swadaya Masyarakat Spanyol (2018) Team Peninjau Telkomsel (2018) Innovatorid pimpinan Budiman Sujatmiko (2019) Pengurus Besar PB IDI (2019) Sekolah Pintar Yayasan Ainun Habibie (2019) Shinkowa Pharmaeutical, Jepang (2019)","title":"Home"},{"location":"#projek-aihub","text":"Visi Misi AIHUB.ID Projek Aihub adalah projek swadaya, kolaborasi bersama antara masyarakat pelaku IT, Pemerintah Daerah, Universitas dan pihak pihak yang bersedia membantu baik dana, infrastruktur ataupun kajian ilmiah. Projek ini tidak terafiliasi kepada partai politik manapun dan pihak pihak manapun. Tujuan aihub adalah membangun sebuah tata kelola Big Data yang portable, mudah dipakai dan mudah diimplementasi dalam ekosistim Big Data menggunakan teknologi Apache Hadoop, Apache Spark, Apache Parquet dan Apache Drill, pustaka Machine Learning Python, Odoo Framework dan lainnya diatas Sistem Operasi Linux (Ubuntu Server) untuk deployment rack to rack ataupun Ubuntu server dengan manajemen container LXD untuk mesin hypervisor Sejarah Projek AIHUB Projek pembuatan sistem tata kelola big data ini dimulai pada bulan February 2017, dengan nama projek Asclepius, yaitu sebuah projek kerjasama antara Dinas Kesehatan Kota Cimahi , Team Ahli IT dari berbagai lapisan masyarakat dan PT. Mediblok Rekatama Indonesia. Tujuan projek Asclepius ini adalah membangun sebuah machine learning kesehatan yang mampu memetakan sebaran penyakit di Kota Cimahi. Projek ini dapat diakses di http://asclepius.medblocks.id . Projek Asclepius selain melibatkan Pemerintah Daerah dan swadaya masyarakat juga dibantu oleh beberapa pihak yaitu PT. Masterweb Network untuk penyediaan infrastruktur dan Telkomsel untuk pengembangan sistem. Sejak tahun 2018, Projek Asclepius ini banyak menyita perhatian masyarakat baik dalam negeri maupun luar negeri, dan dikarenakan oleh saran dari semua pihak maka di tahun 2019 projek ini berubah nama menjadi projek AIHUB yang pengelolaan nya diatur secara swadaya serta melibatkan pihak pihak yang tertarik untuk ikut terlibat dalam pengembangan. Sebagai sebuah projek yang berkesinambungan, projek ini terbuka bagi semua orang yang ingin terlibat, saat ini, pengelolaan projek AIHUB diatur sebagai berikut : Team Teknis Penanggung Jawab Utama , Hardiyanto dari Vision Development Group Singapore Hubungan Masyarakat, Hera Satriono, Perwakilan Swadaya Masyarakat Teknologi Informasi Penanggung jawab Teknis, Whisnu Budhysantika, Perwakilan Swadaya Masyarakat Teknologi Informasi Dewan Pengkajian dan Penelitian : dr. Dwi Agustian, MPH, PhD, Kepala Departemen Ilmu Kesehatan Masyarakat Fakultas Kedokteran Universitas Padjadjaran Bandung Fakultas Kedokteran Universitas Jendral Achmad Yani Cimahi JSPS, Japan Society for Promotion of Science, Jepang Dewan Penasihat : Vina, Septiarani, PhD. Badan Perencanaan Daerah Kota Cimahi dr. Mariya Mubarika Rachman, Staff Khusus Kementrian Kesehatan Indonesia Pihak Sponsor : PT. Masterweb Network Indonesia (2017 - 2018) Telkomsel Indonesia (2018) Shinkowa Pharmaeutical Co. Ltd, Jepang (2019) Press Releases dan kunjungan tamu peninjau BOT, Lembaga Swadaya Masyarakat Spanyol (2018) Team Peninjau Telkomsel (2018) Innovatorid pimpinan Budiman Sujatmiko (2019) Pengurus Besar PB IDI (2019) Sekolah Pintar Yayasan Ainun Habibie (2019) Shinkowa Pharmaeutical, Jepang (2019)","title":"Projek AIHUB"},{"location":"installasi/","text":"Installasi BigQ Manager di Ubuntu 16.04 Server Dalam Ekosistim LXD Rangkaian perintah di buku petunjuk ini dibagi menjadi dua, perintah di host komputer ditandai dengan :host dan perintah di container ditandai dengan :container diasumsikan user yang berada di host adalah myuser dengan host desktop menggunakan sistem operasi Ubuntu Desktop 16.04 atau 18.04 atau 19.04 Installasi LXD LXD mempermudah anda untuk mencoba sistem tata kelola big data Aihub Generasi Kedua, sehingga anda dapat mencobanya di laptop terlebih dahulu. Kebutuhan umum untuk menjalankan sistem ini adalah, Ubuntu 19.04 Desktop atau Ubuntu 18.04 Server dengan ram minimal 16 GB dan prosesor minimal 4 cores, ikuti petunjuk Installasi LXD di host komputer. :host myuser@desktop:~$ sudo snap install lxd Diasumsikan LXD sudah terinstall di host komputer , cek apakah group lxd sudah ada myuser@desktop:~$ groups hasil perintah di atas adalah : myuser adm cdrom sudo dip plugdev lpadmin lxd sambashare cek apakah user myuser sudah masuk ke dalam group lxd myuser@desktop:~$ id hasil dari perintah diatas adalah uid=1000(myuser) gid=1000(myuser) groups=1000(myuser),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),119(lpadmin),**130(lxd)**,131(sambashare) jika myuser belum masuk ke dalam group lxd, lakukan perintah di bawah ini, untuk beberapa kasus harus dilakukan reboot agar user bisa masuk ke dalam group myuser@desktop:~$ usermod -a -G lxd username-di-host myuser@desktop:~$ sudo reboot jalankan inisialisasi lxd myuser@desktop:~$ lxd init Konfigurasi ip address server LXD Setting dhcp lxd server, pada keaadan default interface adalah lxdbr0 . pastikan semua container tidak ada yang jalan! :host myuser@desktop:~$ lxc list myuser@desktop:~$ lxc network edit lxdbr0 rubah ipv4.address dan sesuaikan dengan ip yg dkehendaki, tambahkan dhcp entry bila diperlukan, misalnya seperti dibawah ini config: ipv4.address: 10.10.10.100/24 ipv4.nat: \"true\" ipv6.address: fd42:b943:aa56:2293::1/64 ipv6.nat: \"true\" description: \"\" name: lxdbr0 type: bridge used_by: - /1.0/containers/barebones managed: true status: Created locations: - none jika diperlukan untuk dhcp bisa tambahkan entry ke section config ipv4.dhcp: \"true\" ipv4.dhcp.ranges: 10.10.10.105-10.10.10.120 Reload lxd myuser@desktop:~$ sudo systemctl reload snap.lxd.daemon.service Download dan buat container Barebone-Linux Agar proses cepat, kita akan simpan barebone Ubuntu 16.04 dari images repository ubuntu ke local image sebagai barebone bahan baku :host myuser@desktop:~$ lxc launch ubuntu:16.04 ubuntu myuser@desktop:~$ lxc stop ubuntu myuser@desktop:~$ lxc publish ubuntu -- alias barebone myuser@desktop:~$ lxc image delete ubuntu di tahap ini kita sudah mempunyai image baru bernama barebone Buat Hadoop Container :host myuser@desktop:~$ lxc launch barebone hadoop-raw myuser@desktop:~$ lxc exec hadoop-raw -- /bin/bash Buat user penanggung jawab Hadoop :container root@hadoop-raw:# useradd -m -s /bin/bash hadoop root@hadoop-raw:# passwd hadoop Rubah konfigurasi ssh server edit /etc/ssh/ssh_config Host * StrictHostKeyChecking no SendEnv LANG LC_* HashKnownHosts yes GSSAPIAuthentication yes GSSAPIDelegateCredentials no edit /etc/ssh/sshd_config Port 22 Protocol 2 HostKey /etc/ssh/ssh_host_rsa_key HostKey /etc/ssh/ssh_host_dsa_key HostKey /etc/ssh/ssh_host_ecdsa_key HostKey /etc/ssh/ssh_host_ed25519_key UsePrivilegeSeparation yes KeyRegenerationInterval 3600 ServerKeyBits 1024 SyslogFacility AUTH LogLevel INFO LoginGraceTime 120 PermitRootLogin prohibit-password StrictModes yes RSAAuthentication yes PubkeyAuthentication yes IgnoreRhosts yes RhostsRSAAuthentication no HostbasedAuthentication no PermitEmptyPasswords no ChallengeResponseAuthentication no PasswordAuthentication yes X11Forwarding yes X11DisplayOffset 10 PrintMotd no PrintLastLog yes TCPKeepAlive yes AcceptEnv LANG LC_* Subsystem sftp /usr/lib/openssh/sftp-server UsePAM yes restart ssh server root@hadoop-raw:# /etc/init.d/ssh restart root@hadoop-raw:# exit Setelah exit, login dengan ssh menggunakan hadoop user, untuk mencari ip address dari hadoop raw ini, di komputer host jalankan :host myuser@desktop:~$ lxc list login lah dengan user baru myuser@desktop:~$ ssh hadoop@ipaddress-nya-si-hadoop-raw Upgrade Container :container hadoop@hadoop-raw:~$ sudo apt-get update hadoop@hadoop-raw:~$ sudo apt-get upgrade Sesuaikan Zone Waktu hadoop@hadoop-raw:~$ sudo dpk-reconfigure tzdata Install Java hadoop@hadoop-raw:~$ sudo apt install openjdk-8-jdk hadoop@hadoop-raw:~$ sudo apt-get install openjdk-8-jre Install Hadoop Custom Package download deb package HadoopCustom-2.7.3.deb dan install hadoop@hadoop-raw:~$ cd ~/ hadoop@hadoop-raw:~$ wget https://aihub.id/repository/HadoopCustom-2.7.3.deb hadoop@hadoop-raw:~$ sudo dpkg -i ~/HadoopCustom-2.7.3.deb Hadoop custom ini akan terinstall di /opt/BigQ/hadoop/ edit /etc/environment PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/BigQ/hadoop/bin:/opt/BigQ/hadoop/sbin\" export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64/jre export HADOOP_HOME=/opt/BigQ/hadoop export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre export HADOOP_PREFIX=/opt/BigQ/hadoop export HADOOP_COMMON_LIB_NATIVE_DIR=/opt/BigQ/hadoop/lib/native export HADOOP_OPTS=\"-Djava.library.path=/opt/BigQ/hadoop/lib/native\" Konfigurasi Hadoop edit /opt/BigQ/hadoop/etc/hadoop/core-site.xml <?xml version=\"1.0\" encoding=\"UTF-8\"?> <?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?> <configuration> <property> <name>fs.default.name</name> <value>hdfs://hadoop-raw:9000</value> </property> <property> <name>hadoop.tmp.dir</name> <value>/var/tmp</value> <description>A base for other temporary directories.</description> </property> </configuration> create storage folder hadoop@hadoop-raw:~$ sudo mkdir /var/local/hadoop/ hadoop@hadoop-raw:~$ sudo chown hadoop:hadoop /var/local/hadoop edit /opt/BigQ/hadoop/etc/hadoop/hdfs-site.xml <?xml version=\"1.0\" encoding=\"UTF-8\"?> <?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?> <configuration> <property> <name>dfs.name.dir</name> <value>file:///var/local/hadoop/HDFS/data/namenode</value> </property> <property> <name>dfs.data.dir</name> <value>file:///var/local/hadoop/HDFS/data/datanode</value> </property> <property> <name>dfs.replication</name> <value>1</value> <description>Default block replication.</description> </property> </configuration> edit /opt/BigQ/hadoop/etc/hadoop/mapred-site.xml <configuration> <property> <name>mapreduce.framework.name</name> <value>yarn</value> </property> <property> <name>yarn.app.mapreduce.am.env</name> <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value> </property> <property> <name>mapreduce.map.env</name> <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value> </property> <property> <name>mapreduce.reduce.env</name> <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value> </property> <property> <name>yarn.app.mapreduce.am.resource.mb</name> <value>512</value> </property> <property> <name>mapreduce.map.memory.mb</name> <value>256</value> </property> <property> <name>mapreduce.reduce.memory.mb</name> <value>256</value> </property> <property> <name>mapreduce.jobtracker.address</name> <value>localhost:54311</value> <description>MapReduce job tracker runs at this host and port.</description> </property> </configuration> format hdfs hadoop@hadoop-raw:~$ hadoop namenode -format buat authorized keys untuk akses ke datanode dari hadoop-raw tanpa login, pada saat proses pembuatan key jangan memasukan pass phrase. hadoop@hadoop-raw:~$ ssh-keygen - t rsa hadoop@hadoop-raw:~$ cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys Clean up history dan lainnya hadoop@hadoop-raw:~$ rm ~/HadoopCustom-2.3.1.deb hadoop@hadoop-raw:~$ history -c hadoop@hadoop-raw:~$ exit Create Image Template Hadoop dari Container :host myuser@desktop:~$ lxc stop hadoop-raw myuser@desktop:~$ lxc publish hadoop-raw --alias hadoop-image myuser@desktop:~$ lxc image list myuser@desktop:~$ lxc delete hadoop-raw Sampai dengan tahap ini kita sudah mempunyai beberapa image yaitu barebone dan hadoop-image Installasi Apache Spark :host myuser@desktop:~$ lxc launch hadoop-image spark-raw myuser@desktop:~$ lxc exec spark-raw -- /bin/bash Buat user penanggung jawab Spark :container root@spark-raw:# useradd -m -s /bin/bash spark root@spark-raw:# passwd spark root@spark-raw:# exit Setelah exit, login dengan ssh menggunakan spark user, untuk mencari ip address dari spark-raw ini, di komputer host jalankan :host myuser@desktop:~$ lxc list login lah dengan user baru myuser@desktop:~$ ssh spark@ipaddress-nya-si-spark-raw Install Spark Custom Package :container masih dengan login dengan username spark, download deb package SparkCustom-2.3.1.deb dan install spark@spark-raw:~$ wget http://aihub.id/repository/SparkCustom-2.3.1.deb spark@spark-raw:~$ sudo dpkg -i ~/SparkCustom-2.3.1.deb Spark custom ini akan terinstall di /opt/BigQ/spark/ edit /etc/environment PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/BigQ/hadoop/bin:/opt/BigQ/hadoop/sbin:/opt/BigQ/spark/bin:/opt/BigQ/spark/sbin\" export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64/jre export HADOOP_HOME=/opt/BigQ/hadoop export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre export HADOOP_PREFIX=/opt/BigQ/hadoop export HADOOP_COMMON_LIB_NATIVE_DIR=/opt/BigQ/hadoop/lib/native export HADOOP_OPTS=\"-Djava.library.path=/opt/BigQ/hadoop/lib/native\" export SPARK_HOME=/opt/BigQ/spark export PYSPARK_PYTHON=python3.5 export SPARK_CLASSPATH=/opt/BigQ/spark/jdbc edit /opt/BigQ/spark/spark-env.sh Kosongkan isian SPARK_MASTER_HOST. #!/usr/bin/env bash SPARK_MASTER_HOST= Finishing dan clean up spark@spark-raw:~$ sudo rm /home/hadoop/.ssh/authorized_keys spark@spark-raw:~$ sudo rm /home/hadoop/.ssh/id_rsa spark@spark-raw:~$ sudo /home/hadoop/.ssh/id_rsa.pub spark@spark-raw:~$ sudo echo \"\" > /home/hadoop/.ssh/known_hosts spark@spark-raw:~$ rm ~/SparkCustom-2.3.1.deb spark@spark-raw:~$ history -c spark@spark-raw:~$ exit Create Image Template Spark dari Container :host myuser@desktop:~$ lxc stop spark-raw myuser@desktop:~$ lxc publish spark-raw --alias spark-image myuser@desktop:~$ lxc image list myuser@desktop:~$ lxc delete spark-raw Sampai dengan tahap ini kita sudah mempunyai beberapa image yaitu barebone , spark-image dan hadoop-image Installasi BigQ Manager Front end dari BigQ Manager adalah Odoo Framework 11.0 , untuk membuat container BigQ Manager, yang harus dijadikan bahan baku image adalah spark-image :host myuser@desktop:~$ lxc launch spark-image bigq-raw myuser@desktop:~$ lxc exec bigq-raw -- /bin/bash :container root@bigq-raw:# useradd -m -s /bin/bash masteruser root@bigq-raw:# passwd spark root@bigq-raw:# exit :host lihat ip address bigq-raw dengan cara : myuser@desktop:~$ lxc list login dengan ssh ke dalam bigq-raw dengan menggunakan masteruser. myuser@desktop:~$ ssh masteruser@ipaddress-nya-si-bigq-raw di dalam image baru bigq-raw ini terdapat beberapa user hasil dari pembuatan image hadoop-image dan spark image terdahulu, proses pertama adalah rekonfigurasi server. :container masteruser@bigq-raw:-$ sudo chown -R masteruser:masteruser /opt/BigQ/hadoop masteruser@bigq-raw:-$ sudo chown -R masteruser:masteruser /opt/BigQ/spark masteruser@bigq-raw:-$ sudo rm /var/tmp/* masteruser@bigq-raw:-$ sudo rm -r /var/local/hadoop masteruser@bigq-raw:-$ sudo userdel -r spark masteruser@bigq-raw:-$ sudo userdel -r hadoop Installasi python3 development masteruser@bigq-raw:-$ sudo apt-get install python3-pip masteruser@bigq-raw:-$ sudo apt-get install npm masteruser@bigq-raw:-$ sudo ln -s /usr/bin/nodejs /usr/bin/node masteruser@bigq-raw:-$ sudo npm install -g less less-plugin-clean-css masteruser@bigq-raw:-$ sudo apt-get install node-less masteruser@bigq-raw:-$ sudo apt-get install postgresql Installasi Custom Odoo 11 Server :container masteruser@bigq-raw:-$ sudo adduser --system --home=/opt/BigQ/odoo --group odoo Konfigurasi postgresql buat beberapa user postgres yaitu odoo (user odoo), masteruser (user masteruser) dan jdbcmaster (user yang akan bertindak sebagai proxy lintas komunikasi system BigQ Manager dengan framework Odoo 11) masteruser@bigq-raw:-$ sudo su postgres postgres@bigq-raw:/home/masteruser$ cd postgres@bigq-raw:~$ create user -s odoo postgres@bigq-raw:~$ create user -s masteruser postgres@bigq-raw:~$ create user -s jdbcmaster postgres@bigq-raw:~$ psql postgres=# ALTER USER jdbcmaster WITH PASSWORD 'jdbcmaster'; postgres=# \\q postgres@bigq-raw:~$ exit edit /etc/postgresql/9.5/main/pg_hba.conf local all postgres peer local all odoo peer local all masteruser peer local all jdbcmaster md5 # TYPE DATABASE USER ADDRESS METHOD # \"local\" is for Unix domain socket connections only local all all peer # IPv4 local connections: host all all 127.0.0.1/32 md5 # IPv6 local connections: host all all ::1/128 md5 edit /etc/postgresql/9.5/main/postgresql.conf listen_address = '*' menjadi listen_address = 'localhost' (dan buang '#') restart postgresql masteruser@bigq-raw:-$ sudo /etc/init.d/postgresql restart Test proxy connection dengan user jdbcmaster masteruser@bigq-raw:-$ createdb testing masteruser@bigq-raw:-$ psql testing testing=# \\du testing=# \\q masteruser@bigq-raw:-$ psql -U jdbcmaster -W testing=# \\q masteruser@bigq-raw:-$ dropdb testing masih dengan login dengan username masteruser, download deb package OdooCustom-11.deb dan install masteruser@bigq-raw:-$ cd ~/ masteruser@bigq-raw:-$ wget http://aihub.id/repository/OdooCutom-11.deb masteruser@bigq-raw:-$ sudo dpkg -i ~/OdooCustom-2.3.1.deb Odoo 11 custom ini akan terinstall di /opt/BigQ/odoo/server , download deb package AdditionalConfig-1.0.deb masteruser@bigq-raw:-$ cd ~/ masteruser@bigq-raw:-$ wget http://aihub.id/repository/AdditionalConfig-1.0.deb masteruser@bigq-raw:-$ sudo dpkg -i ~/AdditionalConfig-1.0.deb Installasi AdditionalConfig-1.0.deb tersebut akan menghasilkan beberapa direktori di /opt/BigQ yaitu /opt/BigQ/payload /opt/BigQ/payload/config /opt/BigQ/payload/data /opt/BigQ/payload/images /opt/BigQ/payload/modules /opt/BigQ/payload/scripts Install python library masteruser@bigq-raw:-$ sudo -H pip3 install Cython Babel decorator docutils ebaysdk feedparser gevent greenlet html2text Jinja2 lxml Mako MarkupSafe mock num2words ofxparse passlib Pillow psutil psycogreen pydot pyparsing PyPDF2 pyserial python-dateutil python-openid pytz pyusb PyYAML qrcode reportlab requests six suds-jurko vatnumber vobject Werkzeug XlsxWriter xlwt xlrd psycopg2-binary phonenumbers pandoc gdata Install BigQ Manager Dependencies masteruser@bigq-raw:-$ cd ~/ masteruser@bigq-raw:-$ wget https://aihub.id/repository/pyspark-2.3.1.tar.gz masteruser@bigq-raw:-$ tar -xvf pyspark-2.3.1.tar.gz masteruser@bigq-raw:-$ mv pyspark-2.3.1 pyspark masteruser@bigq-raw:-$ cd pyspark masteruser@bigq-raw:-$ sudo python3 setup.py install masteruser@bigq-raw:-$ sudo -H pip3 install python-dotenv crypthography uuid masteruser@bigq-raw:-$ sudo -H pip3 install pandas==0.24 masteruser@bigq-raw:-$ sudo -H pip3 install pyarrow Test jalankan BigQ Manager masteruser@bigq-raw:-$ /opt/BigQ/odoo/server/odoo-bin :host Di komputer host, download BigQ Manager Data, BigQ Manager Data tersedia dalam beberapa rilis, download sesuai dengan lisensi yang anda punya BigQ_Manager_Standard_V.2.1.zip BigQ_Manager_Government_V.2.1.zip myuser@desktop:-$ cd ~/Download myuser@desktop:-$ wget https://aihub.id/repository/BigQ_Manager_Standard_V.2.1.zip Cari ip address bigq-raw myuser@desktop:-$ lxc list Buka browser (chrome atau Firefox), ketikan url http://ip-address-nya-bigq-raw:8069/web/database/manager Klik button Restore Database, di ops \"Choose File\" klik dan pilih file BigQ Manager Data yang telah didownload sebelumnya (nomor 1-3 sesuai dengan versi release masing masing). Setelah proses restore selesai, loginlah dengan username 'admin' dan password '1234567' jika semua berjalan dengan baik, logout dari system BigQ Manager. Fokuskan kembali ke terminal container yang sedang berjalan dan ketikan ctrl+c dua kali :container Lihat services yang sedang berjalan, dan pastikan hanya port 22 dan 5432 yang masih berjalan masteruser@bigq-raw:-$ netstat -anpt Lakukan pembersihan akhir di container masteruser@bigq-raw:-$ rm ~/OdooCustom-2.3.1.deb masteruser@bigq-raw:-$ rm ~/AdditionalConfig-1.0.deb masteruser@bigq-raw:-$ rm -r ~/pyspark masteruser@bigq-raw:-$ rm pyspark-2.3.1.tar.gz masteruser@bigq-raw:-$ history -c masteruser@bigq-raw:-$ exit :host myuser@desktop:-$ lxc stop bigq-raw myuser@desktop:-$ lxc publish bigq-raw --alias BigQ-image myuser@desktop:-$ lxc delete bigq-raw Sampai dengan tahap ini kita sudah mempunyai beberapa image yaitu barebone , hadoop-image , spark-image dan BigQ-image .","title":"Installasi"},{"location":"installasi/#installasi-bigq-manager-di-ubuntu-1604-server-dalam-ekosistim-lxd","text":"Rangkaian perintah di buku petunjuk ini dibagi menjadi dua, perintah di host komputer ditandai dengan :host dan perintah di container ditandai dengan :container diasumsikan user yang berada di host adalah myuser dengan host desktop menggunakan sistem operasi Ubuntu Desktop 16.04 atau 18.04 atau 19.04","title":"Installasi BigQ Manager di Ubuntu 16.04 Server Dalam Ekosistim LXD"},{"location":"installasi/#installasi-lxd","text":"LXD mempermudah anda untuk mencoba sistem tata kelola big data Aihub Generasi Kedua, sehingga anda dapat mencobanya di laptop terlebih dahulu. Kebutuhan umum untuk menjalankan sistem ini adalah, Ubuntu 19.04 Desktop atau Ubuntu 18.04 Server dengan ram minimal 16 GB dan prosesor minimal 4 cores, ikuti petunjuk Installasi LXD di host komputer. :host myuser@desktop:~$ sudo snap install lxd Diasumsikan LXD sudah terinstall di host komputer , cek apakah group lxd sudah ada myuser@desktop:~$ groups hasil perintah di atas adalah : myuser adm cdrom sudo dip plugdev lpadmin lxd sambashare cek apakah user myuser sudah masuk ke dalam group lxd myuser@desktop:~$ id hasil dari perintah diatas adalah uid=1000(myuser) gid=1000(myuser) groups=1000(myuser),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),119(lpadmin),**130(lxd)**,131(sambashare) jika myuser belum masuk ke dalam group lxd, lakukan perintah di bawah ini, untuk beberapa kasus harus dilakukan reboot agar user bisa masuk ke dalam group myuser@desktop:~$ usermod -a -G lxd username-di-host myuser@desktop:~$ sudo reboot jalankan inisialisasi lxd myuser@desktop:~$ lxd init","title":"Installasi LXD"},{"location":"installasi/#konfigurasi-ip-address-server-lxd","text":"Setting dhcp lxd server, pada keaadan default interface adalah lxdbr0 . pastikan semua container tidak ada yang jalan! :host myuser@desktop:~$ lxc list myuser@desktop:~$ lxc network edit lxdbr0 rubah ipv4.address dan sesuaikan dengan ip yg dkehendaki, tambahkan dhcp entry bila diperlukan, misalnya seperti dibawah ini config: ipv4.address: 10.10.10.100/24 ipv4.nat: \"true\" ipv6.address: fd42:b943:aa56:2293::1/64 ipv6.nat: \"true\" description: \"\" name: lxdbr0 type: bridge used_by: - /1.0/containers/barebones managed: true status: Created locations: - none jika diperlukan untuk dhcp bisa tambahkan entry ke section config ipv4.dhcp: \"true\" ipv4.dhcp.ranges: 10.10.10.105-10.10.10.120 Reload lxd myuser@desktop:~$ sudo systemctl reload snap.lxd.daemon.service","title":"Konfigurasi ip address  server LXD"},{"location":"installasi/#download-dan-buat-container-barebone-linux","text":"Agar proses cepat, kita akan simpan barebone Ubuntu 16.04 dari images repository ubuntu ke local image sebagai barebone bahan baku :host myuser@desktop:~$ lxc launch ubuntu:16.04 ubuntu myuser@desktop:~$ lxc stop ubuntu myuser@desktop:~$ lxc publish ubuntu -- alias barebone myuser@desktop:~$ lxc image delete ubuntu di tahap ini kita sudah mempunyai image baru bernama barebone","title":"Download dan buat container Barebone-Linux"},{"location":"installasi/#buat-hadoop-container","text":":host myuser@desktop:~$ lxc launch barebone hadoop-raw myuser@desktop:~$ lxc exec hadoop-raw -- /bin/bash","title":"Buat Hadoop Container"},{"location":"installasi/#buat-user-penanggung-jawab-hadoop","text":":container root@hadoop-raw:# useradd -m -s /bin/bash hadoop root@hadoop-raw:# passwd hadoop","title":"Buat user penanggung jawab Hadoop"},{"location":"installasi/#rubah-konfigurasi-ssh-server","text":"edit /etc/ssh/ssh_config Host * StrictHostKeyChecking no SendEnv LANG LC_* HashKnownHosts yes GSSAPIAuthentication yes GSSAPIDelegateCredentials no edit /etc/ssh/sshd_config Port 22 Protocol 2 HostKey /etc/ssh/ssh_host_rsa_key HostKey /etc/ssh/ssh_host_dsa_key HostKey /etc/ssh/ssh_host_ecdsa_key HostKey /etc/ssh/ssh_host_ed25519_key UsePrivilegeSeparation yes KeyRegenerationInterval 3600 ServerKeyBits 1024 SyslogFacility AUTH LogLevel INFO LoginGraceTime 120 PermitRootLogin prohibit-password StrictModes yes RSAAuthentication yes PubkeyAuthentication yes IgnoreRhosts yes RhostsRSAAuthentication no HostbasedAuthentication no PermitEmptyPasswords no ChallengeResponseAuthentication no PasswordAuthentication yes X11Forwarding yes X11DisplayOffset 10 PrintMotd no PrintLastLog yes TCPKeepAlive yes AcceptEnv LANG LC_* Subsystem sftp /usr/lib/openssh/sftp-server UsePAM yes restart ssh server root@hadoop-raw:# /etc/init.d/ssh restart root@hadoop-raw:# exit Setelah exit, login dengan ssh menggunakan hadoop user, untuk mencari ip address dari hadoop raw ini, di komputer host jalankan :host myuser@desktop:~$ lxc list login lah dengan user baru myuser@desktop:~$ ssh hadoop@ipaddress-nya-si-hadoop-raw","title":"Rubah konfigurasi ssh server"},{"location":"installasi/#upgrade-container","text":":container hadoop@hadoop-raw:~$ sudo apt-get update hadoop@hadoop-raw:~$ sudo apt-get upgrade","title":"Upgrade Container"},{"location":"installasi/#sesuaikan-zone-waktu","text":"hadoop@hadoop-raw:~$ sudo dpk-reconfigure tzdata","title":"Sesuaikan Zone Waktu"},{"location":"installasi/#install-java","text":"hadoop@hadoop-raw:~$ sudo apt install openjdk-8-jdk hadoop@hadoop-raw:~$ sudo apt-get install openjdk-8-jre","title":"Install Java"},{"location":"installasi/#install-hadoop-custom-package","text":"download deb package HadoopCustom-2.7.3.deb dan install hadoop@hadoop-raw:~$ cd ~/ hadoop@hadoop-raw:~$ wget https://aihub.id/repository/HadoopCustom-2.7.3.deb hadoop@hadoop-raw:~$ sudo dpkg -i ~/HadoopCustom-2.7.3.deb Hadoop custom ini akan terinstall di /opt/BigQ/hadoop/ edit /etc/environment PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/BigQ/hadoop/bin:/opt/BigQ/hadoop/sbin\" export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64/jre export HADOOP_HOME=/opt/BigQ/hadoop export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre export HADOOP_PREFIX=/opt/BigQ/hadoop export HADOOP_COMMON_LIB_NATIVE_DIR=/opt/BigQ/hadoop/lib/native export HADOOP_OPTS=\"-Djava.library.path=/opt/BigQ/hadoop/lib/native\"","title":"Install Hadoop Custom Package"},{"location":"installasi/#konfigurasi-hadoop","text":"edit /opt/BigQ/hadoop/etc/hadoop/core-site.xml <?xml version=\"1.0\" encoding=\"UTF-8\"?> <?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?> <configuration> <property> <name>fs.default.name</name> <value>hdfs://hadoop-raw:9000</value> </property> <property> <name>hadoop.tmp.dir</name> <value>/var/tmp</value> <description>A base for other temporary directories.</description> </property> </configuration> create storage folder hadoop@hadoop-raw:~$ sudo mkdir /var/local/hadoop/ hadoop@hadoop-raw:~$ sudo chown hadoop:hadoop /var/local/hadoop edit /opt/BigQ/hadoop/etc/hadoop/hdfs-site.xml <?xml version=\"1.0\" encoding=\"UTF-8\"?> <?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?> <configuration> <property> <name>dfs.name.dir</name> <value>file:///var/local/hadoop/HDFS/data/namenode</value> </property> <property> <name>dfs.data.dir</name> <value>file:///var/local/hadoop/HDFS/data/datanode</value> </property> <property> <name>dfs.replication</name> <value>1</value> <description>Default block replication.</description> </property> </configuration> edit /opt/BigQ/hadoop/etc/hadoop/mapred-site.xml <configuration> <property> <name>mapreduce.framework.name</name> <value>yarn</value> </property> <property> <name>yarn.app.mapreduce.am.env</name> <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value> </property> <property> <name>mapreduce.map.env</name> <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value> </property> <property> <name>mapreduce.reduce.env</name> <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value> </property> <property> <name>yarn.app.mapreduce.am.resource.mb</name> <value>512</value> </property> <property> <name>mapreduce.map.memory.mb</name> <value>256</value> </property> <property> <name>mapreduce.reduce.memory.mb</name> <value>256</value> </property> <property> <name>mapreduce.jobtracker.address</name> <value>localhost:54311</value> <description>MapReduce job tracker runs at this host and port.</description> </property> </configuration> format hdfs hadoop@hadoop-raw:~$ hadoop namenode -format buat authorized keys untuk akses ke datanode dari hadoop-raw tanpa login, pada saat proses pembuatan key jangan memasukan pass phrase. hadoop@hadoop-raw:~$ ssh-keygen - t rsa hadoop@hadoop-raw:~$ cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys Clean up history dan lainnya hadoop@hadoop-raw:~$ rm ~/HadoopCustom-2.3.1.deb hadoop@hadoop-raw:~$ history -c hadoop@hadoop-raw:~$ exit","title":"Konfigurasi Hadoop"},{"location":"installasi/#create-image-template-hadoop-dari-container","text":":host myuser@desktop:~$ lxc stop hadoop-raw myuser@desktop:~$ lxc publish hadoop-raw --alias hadoop-image myuser@desktop:~$ lxc image list myuser@desktop:~$ lxc delete hadoop-raw Sampai dengan tahap ini kita sudah mempunyai beberapa image yaitu barebone dan hadoop-image","title":"Create Image Template Hadoop dari Container"},{"location":"installasi/#installasi-apache-spark","text":":host myuser@desktop:~$ lxc launch hadoop-image spark-raw myuser@desktop:~$ lxc exec spark-raw -- /bin/bash","title":"Installasi Apache Spark"},{"location":"installasi/#buat-user-penanggung-jawab-spark","text":":container root@spark-raw:# useradd -m -s /bin/bash spark root@spark-raw:# passwd spark root@spark-raw:# exit Setelah exit, login dengan ssh menggunakan spark user, untuk mencari ip address dari spark-raw ini, di komputer host jalankan :host myuser@desktop:~$ lxc list login lah dengan user baru myuser@desktop:~$ ssh spark@ipaddress-nya-si-spark-raw","title":"Buat user penanggung jawab Spark"},{"location":"installasi/#install-spark-custom-package","text":":container masih dengan login dengan username spark, download deb package SparkCustom-2.3.1.deb dan install spark@spark-raw:~$ wget http://aihub.id/repository/SparkCustom-2.3.1.deb spark@spark-raw:~$ sudo dpkg -i ~/SparkCustom-2.3.1.deb Spark custom ini akan terinstall di /opt/BigQ/spark/ edit /etc/environment PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/BigQ/hadoop/bin:/opt/BigQ/hadoop/sbin:/opt/BigQ/spark/bin:/opt/BigQ/spark/sbin\" export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64/jre export HADOOP_HOME=/opt/BigQ/hadoop export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre export HADOOP_PREFIX=/opt/BigQ/hadoop export HADOOP_COMMON_LIB_NATIVE_DIR=/opt/BigQ/hadoop/lib/native export HADOOP_OPTS=\"-Djava.library.path=/opt/BigQ/hadoop/lib/native\" export SPARK_HOME=/opt/BigQ/spark export PYSPARK_PYTHON=python3.5 export SPARK_CLASSPATH=/opt/BigQ/spark/jdbc edit /opt/BigQ/spark/spark-env.sh Kosongkan isian SPARK_MASTER_HOST. #!/usr/bin/env bash SPARK_MASTER_HOST= Finishing dan clean up spark@spark-raw:~$ sudo rm /home/hadoop/.ssh/authorized_keys spark@spark-raw:~$ sudo rm /home/hadoop/.ssh/id_rsa spark@spark-raw:~$ sudo /home/hadoop/.ssh/id_rsa.pub spark@spark-raw:~$ sudo echo \"\" > /home/hadoop/.ssh/known_hosts spark@spark-raw:~$ rm ~/SparkCustom-2.3.1.deb spark@spark-raw:~$ history -c spark@spark-raw:~$ exit","title":"Install Spark Custom Package"},{"location":"installasi/#create-image-template-spark-dari-container","text":":host myuser@desktop:~$ lxc stop spark-raw myuser@desktop:~$ lxc publish spark-raw --alias spark-image myuser@desktop:~$ lxc image list myuser@desktop:~$ lxc delete spark-raw Sampai dengan tahap ini kita sudah mempunyai beberapa image yaitu barebone , spark-image dan hadoop-image","title":"Create Image Template Spark dari Container"},{"location":"installasi/#installasi-bigq-manager","text":"Front end dari BigQ Manager adalah Odoo Framework 11.0 , untuk membuat container BigQ Manager, yang harus dijadikan bahan baku image adalah spark-image :host myuser@desktop:~$ lxc launch spark-image bigq-raw myuser@desktop:~$ lxc exec bigq-raw -- /bin/bash :container root@bigq-raw:# useradd -m -s /bin/bash masteruser root@bigq-raw:# passwd spark root@bigq-raw:# exit :host lihat ip address bigq-raw dengan cara : myuser@desktop:~$ lxc list login dengan ssh ke dalam bigq-raw dengan menggunakan masteruser. myuser@desktop:~$ ssh masteruser@ipaddress-nya-si-bigq-raw di dalam image baru bigq-raw ini terdapat beberapa user hasil dari pembuatan image hadoop-image dan spark image terdahulu, proses pertama adalah rekonfigurasi server. :container masteruser@bigq-raw:-$ sudo chown -R masteruser:masteruser /opt/BigQ/hadoop masteruser@bigq-raw:-$ sudo chown -R masteruser:masteruser /opt/BigQ/spark masteruser@bigq-raw:-$ sudo rm /var/tmp/* masteruser@bigq-raw:-$ sudo rm -r /var/local/hadoop masteruser@bigq-raw:-$ sudo userdel -r spark masteruser@bigq-raw:-$ sudo userdel -r hadoop","title":"Installasi BigQ Manager"},{"location":"installasi/#installasi-python3-development","text":"masteruser@bigq-raw:-$ sudo apt-get install python3-pip masteruser@bigq-raw:-$ sudo apt-get install npm masteruser@bigq-raw:-$ sudo ln -s /usr/bin/nodejs /usr/bin/node masteruser@bigq-raw:-$ sudo npm install -g less less-plugin-clean-css masteruser@bigq-raw:-$ sudo apt-get install node-less masteruser@bigq-raw:-$ sudo apt-get install postgresql","title":"Installasi python3 development"},{"location":"installasi/#installasi-custom-odoo-11-server","text":":container masteruser@bigq-raw:-$ sudo adduser --system --home=/opt/BigQ/odoo --group odoo Konfigurasi postgresql buat beberapa user postgres yaitu odoo (user odoo), masteruser (user masteruser) dan jdbcmaster (user yang akan bertindak sebagai proxy lintas komunikasi system BigQ Manager dengan framework Odoo 11) masteruser@bigq-raw:-$ sudo su postgres postgres@bigq-raw:/home/masteruser$ cd postgres@bigq-raw:~$ create user -s odoo postgres@bigq-raw:~$ create user -s masteruser postgres@bigq-raw:~$ create user -s jdbcmaster postgres@bigq-raw:~$ psql postgres=# ALTER USER jdbcmaster WITH PASSWORD 'jdbcmaster'; postgres=# \\q postgres@bigq-raw:~$ exit edit /etc/postgresql/9.5/main/pg_hba.conf local all postgres peer local all odoo peer local all masteruser peer local all jdbcmaster md5 # TYPE DATABASE USER ADDRESS METHOD # \"local\" is for Unix domain socket connections only local all all peer # IPv4 local connections: host all all 127.0.0.1/32 md5 # IPv6 local connections: host all all ::1/128 md5 edit /etc/postgresql/9.5/main/postgresql.conf listen_address = '*' menjadi listen_address = 'localhost' (dan buang '#') restart postgresql masteruser@bigq-raw:-$ sudo /etc/init.d/postgresql restart Test proxy connection dengan user jdbcmaster masteruser@bigq-raw:-$ createdb testing masteruser@bigq-raw:-$ psql testing testing=# \\du testing=# \\q masteruser@bigq-raw:-$ psql -U jdbcmaster -W testing=# \\q masteruser@bigq-raw:-$ dropdb testing masih dengan login dengan username masteruser, download deb package OdooCustom-11.deb dan install masteruser@bigq-raw:-$ cd ~/ masteruser@bigq-raw:-$ wget http://aihub.id/repository/OdooCutom-11.deb masteruser@bigq-raw:-$ sudo dpkg -i ~/OdooCustom-2.3.1.deb Odoo 11 custom ini akan terinstall di /opt/BigQ/odoo/server , download deb package AdditionalConfig-1.0.deb masteruser@bigq-raw:-$ cd ~/ masteruser@bigq-raw:-$ wget http://aihub.id/repository/AdditionalConfig-1.0.deb masteruser@bigq-raw:-$ sudo dpkg -i ~/AdditionalConfig-1.0.deb Installasi AdditionalConfig-1.0.deb tersebut akan menghasilkan beberapa direktori di /opt/BigQ yaitu /opt/BigQ/payload /opt/BigQ/payload/config /opt/BigQ/payload/data /opt/BigQ/payload/images /opt/BigQ/payload/modules /opt/BigQ/payload/scripts Install python library masteruser@bigq-raw:-$ sudo -H pip3 install Cython Babel decorator docutils ebaysdk feedparser gevent greenlet html2text Jinja2 lxml Mako MarkupSafe mock num2words ofxparse passlib Pillow psutil psycogreen pydot pyparsing PyPDF2 pyserial python-dateutil python-openid pytz pyusb PyYAML qrcode reportlab requests six suds-jurko vatnumber vobject Werkzeug XlsxWriter xlwt xlrd psycopg2-binary phonenumbers pandoc gdata Install BigQ Manager Dependencies masteruser@bigq-raw:-$ cd ~/ masteruser@bigq-raw:-$ wget https://aihub.id/repository/pyspark-2.3.1.tar.gz masteruser@bigq-raw:-$ tar -xvf pyspark-2.3.1.tar.gz masteruser@bigq-raw:-$ mv pyspark-2.3.1 pyspark masteruser@bigq-raw:-$ cd pyspark masteruser@bigq-raw:-$ sudo python3 setup.py install masteruser@bigq-raw:-$ sudo -H pip3 install python-dotenv crypthography uuid masteruser@bigq-raw:-$ sudo -H pip3 install pandas==0.24 masteruser@bigq-raw:-$ sudo -H pip3 install pyarrow Test jalankan BigQ Manager masteruser@bigq-raw:-$ /opt/BigQ/odoo/server/odoo-bin :host Di komputer host, download BigQ Manager Data, BigQ Manager Data tersedia dalam beberapa rilis, download sesuai dengan lisensi yang anda punya BigQ_Manager_Standard_V.2.1.zip BigQ_Manager_Government_V.2.1.zip myuser@desktop:-$ cd ~/Download myuser@desktop:-$ wget https://aihub.id/repository/BigQ_Manager_Standard_V.2.1.zip Cari ip address bigq-raw myuser@desktop:-$ lxc list Buka browser (chrome atau Firefox), ketikan url http://ip-address-nya-bigq-raw:8069/web/database/manager Klik button Restore Database, di ops \"Choose File\" klik dan pilih file BigQ Manager Data yang telah didownload sebelumnya (nomor 1-3 sesuai dengan versi release masing masing). Setelah proses restore selesai, loginlah dengan username 'admin' dan password '1234567' jika semua berjalan dengan baik, logout dari system BigQ Manager. Fokuskan kembali ke terminal container yang sedang berjalan dan ketikan ctrl+c dua kali :container Lihat services yang sedang berjalan, dan pastikan hanya port 22 dan 5432 yang masih berjalan masteruser@bigq-raw:-$ netstat -anpt Lakukan pembersihan akhir di container masteruser@bigq-raw:-$ rm ~/OdooCustom-2.3.1.deb masteruser@bigq-raw:-$ rm ~/AdditionalConfig-1.0.deb masteruser@bigq-raw:-$ rm -r ~/pyspark masteruser@bigq-raw:-$ rm pyspark-2.3.1.tar.gz masteruser@bigq-raw:-$ history -c masteruser@bigq-raw:-$ exit :host myuser@desktop:-$ lxc stop bigq-raw myuser@desktop:-$ lxc publish bigq-raw --alias BigQ-image myuser@desktop:-$ lxc delete bigq-raw Sampai dengan tahap ini kita sudah mempunyai beberapa image yaitu barebone , hadoop-image , spark-image dan BigQ-image .","title":"Installasi Custom Odoo 11 Server"},{"location":"opensource/","text":"Open Source Projek Aihub dibangun diatas fondasi enterprises teknologi yaitu Apache Hadoop, Apache Spark, Apache Parquet, Odoo framework dan secara ektensif menggunakan python library, khususnya yang berkaitan dengan machine learning, big data (hdfs) dan data presentasi, semua komponen adalah open source dengan lisensi yang berbeda beda. Diagram Skematik Skematik Umum AIHUB Generasi Kedua","title":"Teknologi"},{"location":"opensource/#open-source","text":"Projek Aihub dibangun diatas fondasi enterprises teknologi yaitu Apache Hadoop, Apache Spark, Apache Parquet, Odoo framework dan secara ektensif menggunakan python library, khususnya yang berkaitan dengan machine learning, big data (hdfs) dan data presentasi, semua komponen adalah open source dengan lisensi yang berbeda beda.","title":"Open Source"},{"location":"opensource/#diagram-skematik","text":"Skematik Umum AIHUB Generasi Kedua","title":"Diagram Skematik"}]}